{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import time\n",
    "from contextlib import redirect_stdout\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage import transform\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import importlib\n",
    "from src.medsam_segmentation import MedSAMTool\n",
    "from src.data_io import ImageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36642c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_binary_masks(nonbinary_mask):\n",
    "    \"\"\" \n",
    "    Given nonbinary mask which encodes N masks, return N binary masks which\n",
    "    should encode the same information.\n",
    "    \n",
    "    Parameters:\n",
    "        - nonbinary_mask: ndarray of shape (H, W)\n",
    "    Returns:\n",
    "        - binary_masks: ndarray of shape (N, H, W)\n",
    "    \"\"\"\n",
    "    binary_masks = []\n",
    "    for i in np.unique(nonbinary_mask)[1:]:\n",
    "        binary_mask = (nonbinary_mask == i).astype(np.uint8)\n",
    "        binary_masks.append(binary_mask.copy())\n",
    "    binary_masks = np.stack(binary_masks, axis=0)\n",
    "    return binary_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d29e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(modality, exp_type):\n",
    "    query_name = \"X-Ray\" if modality == \"xray\" else \"Dermoscopy\"\n",
    "    imgs_2d_and_3d = os.listdir(os.path.join(os.getcwd(), \"../data/imgs\"))\n",
    "    imgs_2d = [f for f in imgs_2d_and_3d if f.startswith('2D')] # 2803\n",
    "    imgs_2d_modality = [f for f in imgs_2d if query_name in f]    # 50\n",
    "    print(f\"{len(imgs_2d_modality)} images in {modality} modality\")\n",
    "\n",
    "    np.random.seed(42)\n",
    "    split_resulting_len = len(imgs_2d_modality) // 2\n",
    "    val_filenames_bank  = np.random.choice(imgs_2d_modality, size=split_resulting_len, replace=False)\n",
    "    test_filenames_bank = [f for f in imgs_2d_modality if f not in val_filenames_bank]\n",
    "\n",
    "    file_str = f\"{modality}_{exp_type}\"\n",
    "    print(\"Starting experiment\", file_str)\n",
    "\n",
    "    if exp_type.startswith(\"val\"):\n",
    "        filebank = val_filenames_bank\n",
    "    else:\n",
    "        filebank = test_filenames_bank\n",
    "    sample_size = int(exp_type.split(\"_\")[-1])\n",
    "    \n",
    "    # ========================== Unpack ==========================\n",
    "    print(f\"\\nUnpacking {len(filebank)} images...\")\n",
    "    val_raw_imgs, val_raw_boxes, val_raw_gts = [], [], []\n",
    "    for i, img_filename in enumerate(filebank):\n",
    "        img_data = np.load(os.path.join(os.getcwd(), f\"../data/imgs/{img_filename}\"))\n",
    "        mask_data = np.load(os.path.join(os.getcwd(), f\"../data/gts/{img_filename}\"))\n",
    "        \n",
    "        image, boxes, nonbinary_mask = img_data['imgs'], img_data[\"boxes\"], mask_data['gts']\n",
    "        num_masks = 0\n",
    "        for box, mask in zip(boxes, _get_binary_masks(nonbinary_mask)):\n",
    "            x1, y1, x2, y2 = box\n",
    "            box_string = f\"[{x1},{y1},{x2},{y2}]\"\n",
    "            val_raw_imgs.append(image)\n",
    "            val_raw_boxes.append(box_string)\n",
    "            val_raw_gts.append(mask)\n",
    "            num_masks += 1\n",
    "        \n",
    "        print(f\"Processed idx {i}: {img_filename} -> {num_masks} masks\")\n",
    "    print(f\"Finished unpacking images into {len(val_raw_imgs)}.\\n\")\n",
    "\n",
    "    # ========================== Resize ==========================\n",
    "    print(\"Resizing images...\")\n",
    "    random_5_indices = np.random.choice(len(val_raw_imgs), size=sample_size, replace=False)\n",
    "    imgs_to_resize = [val_raw_imgs[i] for i in random_5_indices]\n",
    "    boxes_to_resize = [val_raw_boxes[i] for i in random_5_indices]\n",
    "    gts_to_use = [val_raw_gts[i] for i in random_5_indices]\n",
    "    \n",
    "    resized_imgs, resized_boxes = [], []\n",
    "    resized_gts = gts_to_use\n",
    "    for i, (img_np, box_str) in enumerate(zip(imgs_to_resize, boxes_to_resize)):\n",
    "        if len(img_np.shape) == 2:\n",
    "            img_3c = np.repeat(img_np[:, :, None], 3, axis=-1)\n",
    "        else:\n",
    "            img_3c = img_np\n",
    "\n",
    "        H, W, _ = img_3c.shape\n",
    "\n",
    "        # Resize image to 1024x1024\n",
    "        img_1024 = transform.resize(\n",
    "            img_3c, (1024, 1024), order=3, preserve_range=True, anti_aliasing=True\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "        img_1024 = img_1024 / 255.0\n",
    "        resized_imgs.append(img_1024)\n",
    "\n",
    "        # Scale box to 1024x1024\n",
    "        box_np = np.array([[int(x) for x in box_str[1:-1].split(',')]])\n",
    "        box_scaled = box_np / np.array([W, H, W, H]) * 1024\n",
    "        resized_boxes.append(box_scaled)\n",
    "\n",
    "        print(f\"file {i} | og img shape {img_np.shape} | box_str {box_str} -> {box_scaled.shape}\")\n",
    "\n",
    "    resized_filepath = os.path.join(os.getcwd(), f\"../data/resized_{file_str}.pkl\")\n",
    "    # if file doesn't exist, create it\n",
    "    if not os.path.exists(resized_filepath):\n",
    "        os.makedirs(os.path.dirname(resized_filepath), exist_ok=True)\n",
    "    with open(resized_filepath, \"wb\") as f:\n",
    "        pickle.dump((resized_imgs, resized_boxes, resized_gts), f)\n",
    "    print(f\"Saved resized data to {resized_filepath}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac909ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes 10 mins to run\n",
    "from contextlib import redirect_stdout\n",
    "with open(\"../data/output.log\", \"w\") as f, redirect_stdout(f):\n",
    "    # Your code here\n",
    "    for modality in [\"xray\", \"dermoscopy\"]:\n",
    "        for exp_type in [\"val_filenames_5\", \"test_filenames_25\", \"val_filenames_25\"]:\n",
    "            get_data(modality, exp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(modality):\n",
    "    combined_val, combined_val = None, None\n",
    "    for exp_type in [\"val\", \"test\"]:\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        print(f\"\\n================== Running baseline for {modality}, {exp_type} set ==================\")\n",
    "\n",
    "        resized_filepath = f\"../data/resized_{modality}_{exp_type}_filenames_25.pkl\"\n",
    "        \n",
    "        # ================ Get baseline ================\n",
    "        baseline_start_time = time.time()\n",
    "        print(f\"Reading from {resized_filepath}\")\n",
    "        with open(resized_filepath, \"rb\") as f:\n",
    "            resized_imgs, resized_boxes, resized_gts = pickle.load(f)\n",
    "\n",
    "        segmenter = MedSAMTool(gpu_id=3, checkpoint_path=\"../data/medsam_vit_b.pth\")\n",
    "\n",
    "        used_imgs = resized_imgs\n",
    "        used_boxes = resized_boxes\n",
    "        used_masks = resized_gts\n",
    "\n",
    "        images = ImageData(\n",
    "            raw=used_imgs,\n",
    "            batch_size=min(8, len(used_imgs)),\n",
    "            image_ids=[i for i in range(len(used_imgs))],\n",
    "            masks=used_masks,\n",
    "            predicted_masks=used_masks,\n",
    "        )\n",
    "        is_rgb = modality == \"dermoscopy\"\n",
    "        pred_masks = segmenter.predict(images, used_boxes, used_for_baseline=True, is_rgb=is_rgb)\n",
    "        metrics_dict = segmenter.evaluate(pred_masks, used_masks)\n",
    "\n",
    "        if exp_type == \"val\":\n",
    "            combined_val = metrics_dict['dsc_metric'] + metrics_dict['nsd_metric']\n",
    "            print(f\"Combined metric: {combined_val:.4f}\")\n",
    "\n",
    "        else:\n",
    "            combined_test = metrics_dict['dsc_metric'] + metrics_dict['nsd_metric']\n",
    "            print(f\"Combined metric: {combined_test:.4f}\")\n",
    "\n",
    "        print(f\"Finished running {exp_type} baseline in {time.time() - baseline_start_time:.2f} seconds\")\n",
    "    \n",
    "    # Save the metrics to a file\n",
    "    f\"../data/resized_{modality}_{exp_type}.pkl\"\n",
    "    metrics_filepath = f\"../data/{modality}_baseline_expert.json\"\n",
    "    with open(metrics_filepath, \"w\") as f:\n",
    "        json_output = {\n",
    "            \"expert_baseline_val_avg_metric\": combined_val,\n",
    "            \"expert_baseline_test_avg_metric\": combined_test,\n",
    "        }\n",
    "        json.dump(json_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/get_baselines_output.log\", \"w\") as f, redirect_stdout(f):\n",
    "    for modality in [\"dermoscopy\", \"xray\"]:\n",
    "        get_baseline(modality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
