{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from typing import Optional, Dict, Any, Tuple, List\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import glob\n",
    "from src.data_io import ImageData\n",
    "from src.tools import BaseSegmenter # Added direct import\n",
    "from src.utils import set_gpu_device # Added direct import\n",
    "\n",
    "from cellpose import models, denoise\n",
    "from cellpose.io import imread\n",
    "from cellpose.metrics import average_precision, mask_ious, boundary_scores, aggregated_jaccard_index, flow_error\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.cellpose_segmentation import CellposeTool\n",
    "from src.data_io import ImageData\n",
    "from src.tools import BaseSegmenter # Added direct import\n",
    "\n",
    "from cellpose.io import imread\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "# project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \n",
    "# if project_root not in sys.path:\n",
    "#     sys.path.append(project_root)\n",
    "\n",
    "data_parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"../../../data/updated_cellpose_combined_data/\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PriviligedCellposeTool(BaseSegmenter):\n",
    "    \"\"\"\n",
    "    PriviligedCellposeTool is a class that provides a simple interface for the Cellpose model. \n",
    "    \"\"\"\n",
    "    def __init__(self, model_name: str = \"cyto3\", device: int = 0, channels: List[int] = [2,1], to_normalize: bool = False, model_kwargs: Optional[Dict[str, Any]] = None):\n",
    "        self.model_name = model_name\n",
    "        self.model_kwargs = model_kwargs\n",
    "        self.to_normalize = to_normalize\n",
    "\n",
    "        if device == -1:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = torch.device(f\"cuda:{device}\")\n",
    "\n",
    "        # R: cytoplasm, G: nucleus\n",
    "        self.channels = channels\n",
    "\n",
    "        assert self.model_name in [\"cyto3\", \"denoise_cyto3\"], f\"Model name {self.model_name} not recognized\"\n",
    "\n",
    "        if self.model_name == \"cyto3\":\n",
    "            self.segmenter = models.Cellpose(model_type='cyto3',device=self.device, gpu=True)\n",
    "        elif self.model_name == \"denoise_cyto3\":\n",
    "            self.segmenter = denoise.CellposeDenoiseModel(model_type='cyto3', restore_type='denoise_cyto3', device=self.device, gpu=True)\n",
    "\n",
    "    def predict(self, images: ImageData, batch_size: int = 8) -> Tuple[List[np.ndarray], List[List[np.ndarray]], List[np.ndarray], Any]:\n",
    "        \"\"\"\n",
    "        Predict masks for a batch of images. \n",
    "        Args:\n",
    "            images: ImageData object containing a batch of images. Contains 'raw' and 'masks' attributes in the format of standard ImageData object \n",
    "            [batch_size, height, width, channels]. Images provided must be in the format of standard ImageData object and must have two channels, the first channel being the cytoplasm and the second channel being the nucleus.\n",
    "            batch_size: batch size for prediction\n",
    "        Returns: \n",
    "            masks (List[np.ndarray]): List of labelled images (numpy arrays), where 0=no masks; 1,2,...=mask labels for all pixels in the image\n",
    "        \"\"\"\n",
    "\n",
    "        # Old returns:\n",
    "        # flows (List[List[np.ndarray]]): List of flow outputs per image:\n",
    "        # flows[k][0] = XY flow in HSV 0-255\n",
    "        # flows[k][1] = XY(Z) flows at each pixel\n",
    "        # flows[k][2] = cell probability (if > cellprob_threshold, pixel used for dynamics)\n",
    "        # flows[k][3] = final pixel locations after Euler integration\n",
    "        # styles (List[np.ndarray]): List of style vectors (size 256) summarizing each image\n",
    "        # extra (Any): Diameters if using Cellpose model, input images if using denoise model\n",
    "        to_normalize = self.to_normalize\n",
    "        raw_list=images.raw\n",
    "        if self.model_name == \"cyto3\":\n",
    "            masks, flows, styles, extra = self.segmenter.eval(raw_list, diameter=None, channels=self.channels, normalize=to_normalize, batch_size=batch_size)\n",
    "        elif self.model_name == \"denoise_cyto3\":\n",
    "            masks, flows, styles, extra = self.segmenter.eval(raw_list, diameter=None, channels=self.channels, normalize=to_normalize, batch_size=batch_size)\n",
    "              \n",
    "        return masks#, flows, styles, extra\n",
    "    \n",
    "    def evaluate(self, pred_masks: List[np.ndarray], gt_masks: List[np.ndarray], precision_index: int = 0) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the model.\n",
    "        Args:\n",
    "            pred_masks: predicted masks\n",
    "            gt_masks: ground truth masks\n",
    "        Returns:\n",
    "            metrics: dictionary of metrics. Contains average_precision at IoU thresholds [0.5, 0.75, 0.9]\n",
    "            losses: dictionary of losses. Contains bce_loss\n",
    "        \"\"\"\n",
    "        metrics = {}\n",
    "        losses = {}\n",
    "        ap, tp, fp, fn  = average_precision(pred_masks, gt_masks)\n",
    "        # metrics[\"average_precision\"] = ap.mean(axis=0) # Average over all images\n",
    "        metrics[\"average_precision\"] = np.nanmean(ap, axis=0) # Average over all images\n",
    "        # metrics[\"aggregated_jaccard_index\"] = aggregated_jaccard_index(pred_masks, gt_masks)\n",
    "        # metrics[\"flow_error\"] = flow_error(pred_masks, gt_masks)\n",
    "        # classification loss\n",
    "\n",
    "        spatial_shape = pred_masks[0].shape[0:2]\n",
    "        for x in pred_masks:\n",
    "            if x.shape[0:2] != spatial_shape:\n",
    "                different_spatial_shapes = True\n",
    "                break\n",
    "            else:\n",
    "                different_spatial_shapes = False\n",
    "\n",
    "        if not different_spatial_shapes:\n",
    "            criterion2 = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "            loss2 = criterion2(torch.Tensor(np.array(pred_masks)), torch.from_numpy(np.array(gt_masks )> 0.5).squeeze().float())\n",
    "            losses[\"bce_loss\"] = loss2.item()#/len(pred_masks)\n",
    "        else:\n",
    "            Copycriterion2 = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "            total_loss = 0\n",
    "            for pred, gt in zip(pred_masks, gt_masks):\n",
    "                # Make sure both are tensors with matching dimensions\n",
    "                pred_tensor = torch.Tensor(pred).view(-1)  # Flatten\n",
    "                gt_tensor = torch.from_numpy(gt > 0.5).float().view(-1)  # Flatten\n",
    "                \n",
    "                # Compute loss for this pair\n",
    "                mask_loss = Copycriterion2(pred_tensor, gt_tensor).mean()\n",
    "                total_loss += mask_loss.item()\n",
    "\n",
    "            losses[\"bce_loss\"] = total_loss / len(pred_masks)\n",
    "        \n",
    "        # Let's simplify and only return average precision at [0.5]\n",
    "        return {\"average_precision\": metrics[\"average_precision\"][precision_index].item()}\n",
    "\n",
    "       # return metrics, losses\n",
    "\n",
    "    def preprocess(self, image_data: ImageData) -> ImageData:\n",
    "        \"\"\"We don't need to preprocess the images for Cellpose\"\"\"\n",
    "        return image_data\n",
    "\n",
    "    def loadData(self, data_path: str) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Load the data from the data path and return a tuple of lists of raw images and gt masks, each as numpy arrays\"\"\"\n",
    "        max_val = 65535 # 16-bit images\n",
    "        files = sorted(glob.glob(data_path + '*_img.png'))\n",
    "        raw_images = [(imread(f)).astype(np.float32)/max_val for f in files]\n",
    "        gt_masks = [imread(f.split('.')[0][:-3] + 'masks' + '.' + f.split('.')[1]) for f in files]\n",
    "        gt_masks = [np.expand_dims(mask, axis=2) for mask in gt_masks]\n",
    "        return raw_images, gt_masks\n",
    "    \n",
    "    def loadCombinedDataset(self, data_path: str, dataset_size: int = 256) -> Tuple[List[np.ndarray], List[np.ndarray], List[str]]:\n",
    "        \"\"\"Used with combined datasets.\"\"\"\n",
    "        # Load all images and masks\n",
    "        file = glob.glob(os.path.join(data_path, '*'))\n",
    "        with open(file[0], 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        images = data['images'][:dataset_size]\n",
    "        masks = data['masks'][:dataset_size]\n",
    "        image_ids = data['image_ids'][:dataset_size]\n",
    "        return images, masks, image_ids \n",
    "    \n",
    "    def evaluateDisaggregated(self, imageData_obj: ImageData, avg_precision_idx: int = 0) -> Tuple[Dict[str, float], Dict[str, float]]:\n",
    "        \"\"\"Evaluate the performance of the model on a disaggregated dataset\"\"\"\n",
    "        metrics = {}\n",
    "        losses = {}\n",
    "        pred_masks = imageData_obj.predicted_masks\n",
    "        gt_masks = imageData_obj.masks\n",
    "        ap, tp, fp, fn  = average_precision(pred_masks, gt_masks)\n",
    "\n",
    "        img_source_ids = np.array(imageData_obj.image_ids) \n",
    "        metrics = {'average_precision': np.nanmean(ap, axis=0)[0].item()}\n",
    "\n",
    "        bool_mask = img_source_ids == 'cellpose'\n",
    "        cp_only_ap = ap[bool_mask]  \n",
    "\n",
    "        bool_mask = img_source_ids == 'bact_phase'\n",
    "        bp_only_ap = ap[bool_mask]  \n",
    "\n",
    "        bool_mask = img_source_ids == 'bact_fluor'\n",
    "        bf_only_ap = ap[bool_mask]  \n",
    "\n",
    "        bool_mask = img_source_ids == 'tissuenet'\n",
    "        tn_only_ap = ap[bool_mask]  \n",
    "\n",
    "\n",
    "        per_dataset = {\n",
    "            'cellpose': np.nanmean(cp_only_ap, axis=0)[avg_precision_idx].item(),\n",
    "            'bact_phase': np.nanmean(bp_only_ap, axis=0)[avg_precision_idx].item(),\n",
    "            'bact_fluor': np.nanmean(bf_only_ap, axis=0)[avg_precision_idx].item(),\n",
    "            'tissuenet': np.nanmean(tn_only_ap, axis=0)[avg_precision_idx].item()\n",
    "        }\n",
    "        \n",
    "        metrics['disaggregated_average_precision'] = {}\n",
    "        for name, data in per_dataset.items():\n",
    "            mean_result = np.nanmean(data, axis=0)\n",
    "            value = mean_result \n",
    "            metrics['disaggregated_average_precision'][name] = None if np.isnan(value) else float(value)\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/cellpose/transforms.py:602: UserWarning: 'chan2 (opt)' has value range of ZERO, can instead set chan2 to 0\n",
      "  warnings.warn(\n",
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/cellpose/transforms.py:602: UserWarning: 'chan2 (opt)' has value range of ZERO, can instead set chan2 to 0\n",
      "  warnings.warn(\n",
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/cellpose/transforms.py:602: UserWarning: 'chan2 (opt)' has value range of ZERO, can instead set chan2 to 0\n",
      "  warnings.warn(\n",
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "no seeds found in get_masks_torch - no masks found.\n",
      "no seeds found in get_masks_torch - no masks found.\n",
      "/home/afarhang/miniconda3/envs/sci-agent_opt/lib/python3.10/site-packages/cellpose/metrics.py:132: RuntimeWarning: invalid value encountered in divide\n",
      "  ap[n] = tp[n] / (tp[n] + fp[n] + fn[n])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert_baseline_val: 0.3922841548919678\n",
      "expert_baseline_test: 0.40290507674217224\n"
     ]
    }
   ],
   "source": [
    "# Load Validation and Test Data\n",
    "segmenter = PriviligedCellposeTool(model_name=\"cyto3\", device=5, to_normalize=True)\n",
    "val_data_path = os.path.join(data_parent_dir, \"val_set/\")\n",
    "val_raw_images, val_gt_masks, val_image_sources = segmenter.loadCombinedDataset(data_path=val_data_path, dataset_size=100)\n",
    "\n",
    "test_images_path = os.path.join(data_parent_dir, \"test_set/\")\n",
    "test_raw_images, test_gt_masks, test_image_sources = segmenter.loadCombinedDataset(data_path=test_images_path, dataset_size=808)\n",
    "\n",
    "val_images = ImageData(raw=val_raw_images, batch_size=16, masks=val_gt_masks, image_ids=val_image_sources)\n",
    "test_images = ImageData(raw=test_raw_images, batch_size=16, masks=test_gt_masks, image_ids=test_image_sources)\n",
    "\n",
    "\n",
    "# Evaluate baseline on validation set\n",
    "val_pred_masks = segmenter.predict(val_images)\n",
    "val_images.predicted_masks = val_pred_masks\n",
    "val_metrics = segmenter.evaluate(val_pred_masks, val_gt_masks)\n",
    "expert_baseline_val = val_metrics[\"average_precision\"]\n",
    "# # Evaluate baseline on test set\n",
    "test_pred_masks = segmenter.predict(test_images)\n",
    "test_images.predicted_masks = test_pred_masks\n",
    "test_metrics = segmenter.evaluate(test_pred_masks, test_gt_masks)\n",
    "expert_baseline_test = test_metrics[\"average_precision\"]\n",
    "\n",
    "print(f\"expert_baseline_val: {expert_baseline_val}\")\n",
    "print(f\"expert_baseline_test: {expert_baseline_test}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-agent_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
